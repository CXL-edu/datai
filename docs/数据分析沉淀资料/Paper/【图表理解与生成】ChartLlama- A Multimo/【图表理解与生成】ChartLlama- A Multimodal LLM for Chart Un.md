# 【图表理解与生成】ChartLlama: A Multimodal LLM for Chart Understanding and Generation

[ChartLlama: A Multimodal LLM for Chart Understanding and Generation](https://tingxueronghua.github.io/ChartLlama/ "ChartLlama: A Multimodal LLM for Chart Understanding and Generation")

# 1. 论文概述

多模态大模型（Multi-modal large language models，MLLM）在 视觉-语言 任务上展示了优越的性能。但是，它们通常缺乏理解特定领域数据的能力，尤其是解释数据图表。主要原因是缺乏相关的多模态指令微调数据集。本文使用GPT-4生成指令微调数据集，开发了一个多步数据生成流程，在不同步骤可靠的生成表格数据、创建数据图，并分别设计指令微调数据。使得以低成本，持续和高效的生成多样化、高质量的数据。在 23年12月 ChartLlama 在ChartQA, Chart-to-text 和 Chart-extraction 这三个 benchmark 达到了SOTA效果，并在自定义的不同的数据图和任务上达到了远超baseline的效果

涉及专门收集数据以完善理解图表的指令存在几个挑战。通常源于两个领域：理解和生成。有效的图表理解模型应能够从各种图表中提取和汇总数据，并根据这些信息进行预测。

现存数据集仅提供简单的问答或者生成标题，主要是因为缺乏详细图表信息和对原始数据的高级理解。且高度依赖对图表进行手动注解，因为直接使用网络爬虫获取的样本可能会带来低质量的负影响。对图表进行广泛和深入的注解，对注解人员具有较大挑战。相比于图表理解，生成图表是一个更具有挑战的任务，即使现在模型的生图能力在不断增强，大模型对数据还是很容易产生幻觉，生成 python 代码是更有前景的方向，但是需要大量的标注数据。网上的数据图表通常缺乏真实数据和代码注解。这些问题阻碍了模型理解和生成数据图表。

本文提出的**图表理解和生成的数据采集方法**，包含三个阶段：

（1）**图表数据生成**：直接给定特定的特征，如主题、分布、趋势，让 GPT-4 生成合成数据。不用受限于从传统数据源采集数据，如网络爬虫和现存数据集。该方案的灵活性使其可以生成多样化和精确的数据。

（2）**图表生成**：随后，GPT-4 使用生成的图表数据和绘图库的文档，生成绘图的代码脚本，然后使用脚本和数据渲染出结果。结果是精心渲染的图表的集合，这些图表涵盖了各种形式，每个图表都准确地代表其基础数据。

（3）**指令数据生成**：除了图表渲染，使用 GPT-4 进一步解释和描述图表内容，确保对图表的整体理解。GPT-4 被提示对图表生成相关的问答对。最终形成了一个全面的指令微调语料库，整合了对图表的描述文本、问答对以及用于绘图的原始或修改后的代码。

最终，作者使用该方法生成了图表数据集：

使用本文数据集训练，使得Chartllama配备了几种独特的功能，包括支持更广泛的图表类型的能力，跨多个图表推断，执行图表删除范围任务，甚至编辑图表图。

论文贡献：

（1）基于模型合成数据的方法具有较高的灵活性和可拓展性，可以容易的迁移到不同的图表和任务。（但是受限于模型已有知识）

（2）图表数据 benchmark（3）图表理解和生成模型 ChartLlama，基于 LLaVA-1.5 通过 SFT 得到

# 2. 图表理解—相关工作

之前的图表理解相关数据集【论文参考文献】主要划为两类。一类是图表问答任务，如由人类标注的ChartQA，由模板生成的PlotQA，这些数据集的优点在于它们的数据量较大。但是，他们的局限性包括确保问题和答案质量的难以保证，以及倾向于过多地关注图表中数据的简单问题。另一类是转换图表到文本描述（即Chart-to-text），这些数据集的图表和注解是从真实世界获取的，保证了其高质量，并鼓励模型挖掘图表背后的趋势和意义，其缺点是对图表的文本描述中可能存在更多噪声，且过于依赖BLEU-4。

之前的图表理解任务也可划为两类，一类是使用单个模型去理解图表并以文本回答，另一类是使用模型将图表转换为结构化数据，然后基于该数据使用大模型分析和回答问题。在 Chartllama 中主要是第一类任务，使用单个模型完成全部图表理解过程。

# 3. 图表数据集生成方法

## 图表数据生成

目标是采集高质量和多样性的表格数据。
